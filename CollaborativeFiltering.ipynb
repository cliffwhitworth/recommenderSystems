{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "https://surprise.readthedocs.io/en/stable/getting_started.html<br />\n",
    "https://sundog-education.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Surprise docs getting started\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "fullTrainSet = data.build_full_trainset()\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our movie id, movie names arrays\n",
    "from surprise import get_dataset_dir\n",
    "\n",
    "rid_to_name = {}\n",
    "name_to_rid = {}\n",
    "\n",
    "file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "with open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "    for line in f:\n",
    "        line = line.split('|')\n",
    "        rid_to_name[line[0]] = line[1]\n",
    "        name_to_rid[line[1]] = line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L.A. Confidential (1997)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rid_to_name['302']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'302'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_rid['L.A. Confidential (1997)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get name of movie based on id\n",
    "def getMovieName(movieID):\n",
    "    if movieID in rid_to_name:\n",
    "        return rid_to_name[movieID]\n",
    "    else:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our user data\n",
    "from surprise import Reader\n",
    "\n",
    "file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.data'\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "data = Dataset.load_from_file(file_name, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "ratings = defaultdict(int)\n",
    "rankings = defaultdict(int)\n",
    "with open(file_name, newline='') as csvfile:\n",
    "    ratingReader = csv.reader(csvfile)\n",
    "    next(ratingReader)\n",
    "    for row in ratingReader:\n",
    "        rowArray = str(row[0]).split('\\t')\n",
    "        movieID = int(rowArray[1])\n",
    "        ratings[movieID] += 1\n",
    "rank = 1\n",
    "for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "    rankings[movieID] = rank\n",
    "    rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of movies already seen by uid\n",
    "testUserInnerID = trainset.to_inner_uid(uid)\n",
    "watched = {}\n",
    "for itemID, rating in trainset.ur[testUserInnerID]:\n",
    "    watched[itemID] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Item-based collaborative filtering\n",
    "from surprise import KNNBasic\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False\n",
    "               }\n",
    "\n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopN(predictions, n=10, minimumRating=4.0):\n",
    "    topN = defaultdict(list)\n",
    "\n",
    "    for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
    "        if (estimatedRating >= minimumRating):\n",
    "            topN[int(userID)].append((int(movieID), estimatedRating))\n",
    "\n",
    "    for userID, ratings in topN.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        topN[int(userID)] = ratings[:n]\n",
    "\n",
    "    return topN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitRate(topNPredicted, leftOutPredictions):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "\n",
    "    # For each left-out rating\n",
    "    for leftOut in leftOutPredictions:\n",
    "        userID = leftOut[0]\n",
    "        leftOutMovieID = leftOut[1]\n",
    "        # Is it in the predicted top 10 for this user?\n",
    "        hit = False\n",
    "        for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "            if (int(leftOutMovieID) == int(movieID)):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit) :\n",
    "            hits += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    # Compute overall precision\n",
    "    return hits/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulativeHitRate(topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "\n",
    "    # For each left-out rating\n",
    "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "        # Only look at ability to recommend things the users actually liked...\n",
    "        if (actualRating >= ratingCutoff):\n",
    "            # Is it in the predicted top 10 for this user?\n",
    "            hit = False\n",
    "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "                if (int(leftOutMovieID) == movieID):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit) :\n",
    "                hits += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "    # Compute overall precision\n",
    "    return hits/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratingHitRate(topNPredicted, leftOutPredictions):\n",
    "    hits = defaultdict(float)\n",
    "    total = defaultdict(float)\n",
    "\n",
    "    # For each left-out rating\n",
    "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "        # Is it in the predicted top N for this user?\n",
    "        hit = False\n",
    "        for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "            if (int(leftOutMovieID) == movieID):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit) :\n",
    "            hits[actualRating] += 1\n",
    "\n",
    "        total[actualRating] += 1\n",
    "\n",
    "    # Compute overall precision\n",
    "    for rating in sorted(hits.keys()):\n",
    "        print (rating, hits[rating] / total[rating])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageReciprocalHitRank(topNPredicted, leftOutPredictions):\n",
    "    summation = 0\n",
    "    total = 0\n",
    "    # For each left-out rating\n",
    "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "        # Is it in the predicted top N for this user?\n",
    "        hitRank = 0\n",
    "        rank = 0\n",
    "        for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "            rank = rank + 1\n",
    "            if (int(leftOutMovieID) == movieID):\n",
    "                hitRank = rank\n",
    "                break\n",
    "        if (hitRank > 0) :\n",
    "            summation += 1.0 / hitRank\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    return summation / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userCoverage(topNPredicted, numUsers, ratingThreshold=0):\n",
    "    hits = 0\n",
    "    for userID in topNPredicted.keys():\n",
    "        hit = False\n",
    "        for movieID, predictedRating in topNPredicted[userID]:\n",
    "            if (predictedRating >= ratingThreshold):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit):\n",
    "            hits += 1\n",
    "\n",
    "    return hits / numUsers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# https://docs.python.org/2/library/itertools.html\n",
    "\n",
    "def diversity(topNPredicted, simsAlgo):\n",
    "    n = 0\n",
    "    total = 0\n",
    "    simsMatrix = simsAlgo.compute_similarities()\n",
    "    for userID in topNPredicted.keys():\n",
    "        pairs = itertools.combinations(topNPredicted[userID], 2)\n",
    "        for pair in pairs:\n",
    "            movie1 = pair[0][0]\n",
    "            movie2 = pair[1][0]\n",
    "            innerID1 = simsAlgo.trainset.to_inner_iid(str(movie1))\n",
    "            innerID2 = simsAlgo.trainset.to_inner_iid(str(movie2))\n",
    "            similarity = simsMatrix[innerID1][innerID2]\n",
    "            total += similarity\n",
    "            n += 1\n",
    "\n",
    "    S = total / n\n",
    "    return (1-S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novelty(topNPredicted, rankings):\n",
    "    n = 0\n",
    "    total = 0\n",
    "    for userID in topNPredicted.keys():\n",
    "        for rating in topNPredicted[userID]:\n",
    "            movieID = rating[0]\n",
    "            rank = rankings[movieID]\n",
    "            total += rank\n",
    "            n += 1\n",
    "    return total / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import LeaveOneOut\n",
    "\n",
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "\n",
    "for trainSet, testSet in LOOCV.split(data):\n",
    "    model.fit(trainSet)\n",
    "    leftOutPredictions = model.test(testSet)\n",
    "    bigTestSet = trainSet.build_anti_testset()\n",
    "    allPredictions = model.test(bigTestSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0257\n",
      "1.0256932211196677\n",
      "MAE:  0.8129\n",
      "0.8129226009037279\n",
      "Hit Rate: 0.0042417815482502655\n",
      "Rating Hit Rate:\n",
      "2.0 0.009174311926605505\n",
      "3.0 0.004424778761061947\n",
      "5.0 0.008849557522123894\n",
      "Cumulative Hit Rate: 0.003703703703703704\n",
      "Average Reciprocal Hit Rate: 0.0006480499587604572\n",
      "User Coverage: 0.9045599151643691\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Diversity: 0.5569158930082343\n",
      "Novelty: 1291.7522355207043\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "from collections import defaultdict\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import LeaveOneOut\n",
    "\n",
    "print(accuracy.rmse(predictions))\n",
    "print(accuracy.mae(predictions))\n",
    "topNPredicted = getTopN(allPredictions, n=10)\n",
    "print('Hit Rate:', hitRate(topNPredicted, leftOutPredictions))\n",
    "print('Rating Hit Rate:')\n",
    "ratingHitRate(topNPredicted, leftOutPredictions)\n",
    "print('Cumulative Hit Rate:', cumulativeHitRate(topNPredicted, leftOutPredictions, 4.0))\n",
    "print('Average Reciprocal Hit Rate:', averageReciprocalHitRank(topNPredicted, leftOutPredictions))\n",
    "print('User Coverage:', userCoverage(topNPredicted, fullTrainSet.n_users, ratingThreshold=4.0))\n",
    "print('Diversity:', diversity(topNPredicted, model))\n",
    "print('Novelty:', novelty(topNPredicted, rankings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0321  1.0238  1.0265  1.0256  1.0282  1.0272  0.0028  \n",
      "MAE (testset)     0.8149  0.8086  0.8121  0.8106  0.8142  0.8121  0.0023  \n",
      "Fit time          3.84    3.84    3.83    3.97    3.84    3.86    0.05    \n",
      "Test time         7.35    7.95    8.43    8.46    12.31   8.90    1.75    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.03211842, 1.02378482, 1.02647282, 1.02558141, 1.0282013 ]),\n",
       " 'test_mae': array([0.81494059, 0.8085966 , 0.81209358, 0.81056179, 0.81422078]),\n",
       " 'fit_time': (3.8368287086486816,\n",
       "  3.836512565612793,\n",
       "  3.8317837715148926,\n",
       "  3.965705633163452,\n",
       "  3.8419413566589355),\n",
       " 'test_time': (7.354872465133667,\n",
       "  7.945512533187866,\n",
       "  8.429388284683228,\n",
       "  8.46420931816101,\n",
       "  12.307350397109985)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 5-fold cross-validation and compare\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Define matrix and similarityRow\n",
    "simsMatrix = model.compute_similarities()\n",
    "similarityRow = simsMatrix[testUserInnerID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build testUserRatings\n",
    "testUserRatings = trainset.ur[testUserInnerID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build kNeighbors\n",
    "import heapq\n",
    "# https://docs.python.org/2/library/heapq.html\n",
    "\n",
    "k = 10\n",
    "kNeighbors = heapq.nlargest(k, testUserRatings, key=lambda t: t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get similar items weighted by rating\n",
    "from collections import defaultdict\n",
    "\n",
    "similarItems = defaultdict(float)\n",
    "for itemID, rating in kNeighbors:\n",
    "    similarityRow = simsMatrix[itemID]\n",
    "    for innerID, score in enumerate(similarityRow):\n",
    "        similarItems[innerID] += score * (rating / 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618 Picnic (1955) 9.039175091983846\n",
      "370 Mary Reilly (1996) 9.038191493346249\n",
      "672 Candyman (1992) 8.978452627580609\n",
      "305 Ice Storm, The (1997) 8.97136541681037\n",
      "1058 War, The (1994) 8.970819518792984\n",
      "499 Cat on a Hot Tin Roof (1958) 8.96708000230137\n",
      "768 Casper (1995) 8.965292743436809\n",
      "510 Magnificent Seven, The (1954) 8.95716246707514\n",
      "942 What's Love Got to Do with It (1993) 8.954475667135616\n",
      "1357 For the Moment (1994) 8.947485625254105\n",
      "725 Exit to Eden (1994) 8.945884759369367\n"
     ]
    }
   ],
   "source": [
    "# Print top-rated items from similar items\n",
    "from operator import itemgetter\n",
    "# https://docs.python.org/3/library/operator.html\n",
    "\n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(similarItems.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        movieID = trainset.to_raw_iid(itemID)\n",
    "        print(movieID, getMovieName(movieID), ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748 Saint, The (1997) 16.0002160873711\n",
      "618 Picnic (1955) 15.990649640672036\n",
      "1184 Endless Summer 2, The (1994) 15.949333677769713\n",
      "573 Body Snatchers (1993) 15.839895216412046\n",
      "484 Maltese Falcon, The (1941) 15.823959057704087\n",
      "288 Scream (1996) 15.80484953861616\n",
      "1255 Broken English (1996) 15.788503592811475\n",
      "120 Striptease (1996) 15.784897714443504\n",
      "746 Real Genius (1985) 15.758042964077784\n",
      "625 Sword in the Stone, The (1963) 15.72287151851038\n",
      "708 Sex, Lies, and Videotape (1989) 15.719226107760083\n"
     ]
    }
   ],
   "source": [
    "# Aternative Tuning\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "kNeighbors = []\n",
    "for rating in testUserRatings:\n",
    "    if rating[1] >= 4.0:\n",
    "        kNeighbors.append(rating)\n",
    "    \n",
    "similarItemsAlt = defaultdict(float)\n",
    "for itemID, rating in kNeighbors:\n",
    "    similarityRow = simsMatrix[itemID]\n",
    "    for innerID, score in enumerate(similarityRow):\n",
    "        similarItemsAlt[innerID] += score * (rating / 5.0)\n",
    "        \n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(similarItemsAlt.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        movieID = trainset.to_raw_iid(itemID)\n",
    "        print(movieID, getMovieName(movieID), ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# User-based collaborative filtering\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True\n",
    "               }\n",
    "\n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Define similarityRow\n",
    "simsMatrix = model.compute_similarities()\n",
    "similarityRow = simsMatrix[testUserInnerID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top K users\n",
    "import heapq\n",
    "\n",
    "k = 10\n",
    "TopKUsers = []\n",
    "for innerID, score in enumerate(similarityRow):\n",
    "    if (innerID != testUserInnerID):\n",
    "        TopKUsers.append( (innerID, score) )\n",
    "\n",
    "kNeighbors = heapq.nlargest(k, TopKUsers, key=lambda t: t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add up ratings weighted by user similarity\n",
    "similarUsers = defaultdict(float)\n",
    "for similarUser in kNeighbors:\n",
    "    innerID = similarUser[0]\n",
    "    userSimilarityScore = similarUser[1]\n",
    "    theirRatings = trainset.ur[innerID]\n",
    "    for rating in theirRatings:\n",
    "        similarUsers[rating[0]] += (rating[1] / 5.0) * userSimilarityScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258 Contact (1997) 4.6000000000000005\n",
      "181 Return of the Jedi (1983) 4.6\n",
      "300 Air Force One (1997) 4.0\n",
      "127 Godfather, The (1972) 3.5999999999999996\n",
      "288 Scream (1996) 3.4000000000000004\n",
      "50 Star Wars (1977) 3.4\n",
      "323 Dante's Peak (1997) 3.2\n",
      "100 Fargo (1996) 3.0\n",
      "343 Alien: Resurrection (1997) 3.0\n",
      "405 Mission: Impossible (1996) 2.8000000000000003\n",
      "271 Starship Troopers (1997) 2.8\n"
     ]
    }
   ],
   "source": [
    "# Print top-rated items from similar users\n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(similarUsers.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        movieID = trainset.to_raw_iid(itemID)\n",
    "        print(movieID, getMovieName(movieID), ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 Return of the Jedi (1983) 55.60000000000001\n",
      "174 Raiders of the Lost Ark (1981) 55.6\n",
      "100 Fargo (1996) 55.6\n",
      "204 Back to the Future (1985) 50.00000000000001\n",
      "50 Star Wars (1977) 49.99999999999999\n",
      "172 Empire Strikes Back, The (1980) 47.2\n",
      "1 Toy Story (1995) 46.4\n",
      "79 Fugitive, The (1993) 45.4\n",
      "98 Silence of the Lambs, The (1991) 42.4\n",
      "11 Seven (Se7en) (1995) 42.199999999999996\n",
      "237 Jerry Maguire (1996) 42.199999999999996\n"
     ]
    }
   ],
   "source": [
    "# Aternative Tuning\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "kNeighbors = []\n",
    "for rating in testUserRatings:\n",
    "    if rating[1] >= .95:\n",
    "        kNeighbors.append(rating)\n",
    "    \n",
    "similarUsers = defaultdict(float)\n",
    "for similarUser in kNeighbors:\n",
    "    innerID = similarUser[0]\n",
    "    userSimilarityScore = similarUser[1]\n",
    "    theirRatings = trainset.ur[innerID]\n",
    "    for rating in theirRatings:\n",
    "        similarUsers[rating[0]] += (rating[1] / 5.0) * userSimilarityScore\n",
    "        \n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(similarUsers.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        movieID = trainset.to_raw_iid(itemID)\n",
    "        print(movieID, getMovieName(movieID), ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0200  1.0218  1.0170  1.0086  1.0151  1.0165  0.0046  \n",
      "MAE (testset)     0.8053  0.8101  0.8054  0.7944  0.8039  0.8038  0.0052  \n",
      "Fit time          2.34    2.00    2.93    3.27    2.03    2.51    0.50    \n",
      "Test time         6.74    7.71    7.91    7.69    7.49    7.51    0.41    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.01996277, 1.02184076, 1.01701131, 1.00859677, 1.01505836]),\n",
       " 'test_mae': array([0.80534471, 0.81014095, 0.80543123, 0.79441833, 0.80388233]),\n",
       " 'fit_time': (2.3406484127044678,\n",
       "  2.0002520084381104,\n",
       "  2.9340782165527344,\n",
       "  3.2667782306671143,\n",
       "  2.0318381786346436),\n",
       " 'test_time': (6.738163471221924,\n",
       "  7.712613105773926,\n",
       "  7.91057276725769,\n",
       "  7.6912925243377686,\n",
       "  7.494473695755005)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 5-fold cross-validation and compare\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 4.00   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# Single prediction\n",
    "pred = model.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
